{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is my capstone project for the Udacity Machine Learning Nanodegree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the libraries needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras as kr\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directory = 'sandp500/individual_stocks_5yr'\n",
    "#directory = '/OneDrive/Documents/Projects/MachineLearning/Udacity/Capstone/sandp500/individual_stocks_5yr'\n",
    "dir_listing = listdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504\n",
      "AAL\n"
     ]
    }
   ],
   "source": [
    "symbols_list = []\n",
    "\n",
    "for symbol in dir_listing:\n",
    "    symb = symbol.split('_')[0]\n",
    "    symbols_list.append(symb)\n",
    "\n",
    "print(len(symbols_list))\n",
    "print(symbols_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_file = '{}/{}_data.csv'.format(directory, symbols_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we already know the name of the specific stock we are trying to get from the name of the file, we can drop that column in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = dataset.assign(trading_date = pd.to_datetime(dataset['Date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# below code is copied from: https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/\n",
    "\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = pd.DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = pd.concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Name</th>\n",
       "      <th>trading_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-12-09</td>\n",
       "      <td>23.85</td>\n",
       "      <td>25.44</td>\n",
       "      <td>23.45</td>\n",
       "      <td>24.60</td>\n",
       "      <td>43197268</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-12-10</td>\n",
       "      <td>24.50</td>\n",
       "      <td>25.17</td>\n",
       "      <td>24.41</td>\n",
       "      <td>24.88</td>\n",
       "      <td>18660625</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-12-11</td>\n",
       "      <td>25.48</td>\n",
       "      <td>27.20</td>\n",
       "      <td>25.37</td>\n",
       "      <td>25.99</td>\n",
       "      <td>38843371</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-12-12</td>\n",
       "      <td>26.20</td>\n",
       "      <td>26.71</td>\n",
       "      <td>25.45</td>\n",
       "      <td>25.45</td>\n",
       "      <td>19981824</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-12-13</td>\n",
       "      <td>25.75</td>\n",
       "      <td>26.30</td>\n",
       "      <td>25.52</td>\n",
       "      <td>26.23</td>\n",
       "      <td>12192421</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013-12-16</td>\n",
       "      <td>26.63</td>\n",
       "      <td>26.77</td>\n",
       "      <td>26.35</td>\n",
       "      <td>26.61</td>\n",
       "      <td>13190945</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013-12-17</td>\n",
       "      <td>26.48</td>\n",
       "      <td>26.59</td>\n",
       "      <td>25.95</td>\n",
       "      <td>26.10</td>\n",
       "      <td>11413199</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013-12-18</td>\n",
       "      <td>25.99</td>\n",
       "      <td>26.23</td>\n",
       "      <td>25.55</td>\n",
       "      <td>26.23</td>\n",
       "      <td>9994162</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2013-12-19</td>\n",
       "      <td>26.12</td>\n",
       "      <td>26.49</td>\n",
       "      <td>25.82</td>\n",
       "      <td>26.12</td>\n",
       "      <td>6916497</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2013-12-20</td>\n",
       "      <td>26.18</td>\n",
       "      <td>26.49</td>\n",
       "      <td>26.14</td>\n",
       "      <td>26.33</td>\n",
       "      <td>8530924</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2013-12-23</td>\n",
       "      <td>26.29</td>\n",
       "      <td>26.49</td>\n",
       "      <td>26.05</td>\n",
       "      <td>26.18</td>\n",
       "      <td>5403084</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2013-12-24</td>\n",
       "      <td>26.00</td>\n",
       "      <td>26.26</td>\n",
       "      <td>26.00</td>\n",
       "      <td>26.25</td>\n",
       "      <td>2652974</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2013-12-26</td>\n",
       "      <td>26.12</td>\n",
       "      <td>26.36</td>\n",
       "      <td>25.98</td>\n",
       "      <td>26.13</td>\n",
       "      <td>4226639</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2013-12-27</td>\n",
       "      <td>25.95</td>\n",
       "      <td>26.10</td>\n",
       "      <td>24.91</td>\n",
       "      <td>24.94</td>\n",
       "      <td>13227018</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2013-12-30</td>\n",
       "      <td>24.87</td>\n",
       "      <td>25.25</td>\n",
       "      <td>24.65</td>\n",
       "      <td>24.78</td>\n",
       "      <td>8841369</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2013-12-31</td>\n",
       "      <td>24.74</td>\n",
       "      <td>25.25</td>\n",
       "      <td>24.63</td>\n",
       "      <td>25.25</td>\n",
       "      <td>7168395</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2013-12-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2014-01-02</td>\n",
       "      <td>25.07</td>\n",
       "      <td>25.82</td>\n",
       "      <td>25.06</td>\n",
       "      <td>25.36</td>\n",
       "      <td>8998943</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2014-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2014-01-03</td>\n",
       "      <td>25.75</td>\n",
       "      <td>26.75</td>\n",
       "      <td>25.51</td>\n",
       "      <td>26.54</td>\n",
       "      <td>13836062</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2014-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2014-01-06</td>\n",
       "      <td>26.62</td>\n",
       "      <td>27.20</td>\n",
       "      <td>26.60</td>\n",
       "      <td>27.03</td>\n",
       "      <td>11272273</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2014-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2014-01-07</td>\n",
       "      <td>27.20</td>\n",
       "      <td>27.40</td>\n",
       "      <td>26.67</td>\n",
       "      <td>26.90</td>\n",
       "      <td>11288775</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2014-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2014-01-08</td>\n",
       "      <td>26.37</td>\n",
       "      <td>27.68</td>\n",
       "      <td>26.35</td>\n",
       "      <td>27.63</td>\n",
       "      <td>15736891</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2014-01-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2014-01-09</td>\n",
       "      <td>28.24</td>\n",
       "      <td>29.60</td>\n",
       "      <td>28.20</td>\n",
       "      <td>29.42</td>\n",
       "      <td>26056445</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2014-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2014-01-10</td>\n",
       "      <td>29.05</td>\n",
       "      <td>29.83</td>\n",
       "      <td>28.75</td>\n",
       "      <td>29.35</td>\n",
       "      <td>12824160</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2014-01-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2014-01-13</td>\n",
       "      <td>29.18</td>\n",
       "      <td>29.53</td>\n",
       "      <td>28.58</td>\n",
       "      <td>28.65</td>\n",
       "      <td>10591701</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2014-01-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2014-01-14</td>\n",
       "      <td>28.75</td>\n",
       "      <td>29.04</td>\n",
       "      <td>28.71</td>\n",
       "      <td>28.87</td>\n",
       "      <td>10601529</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2014-01-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2014-01-15</td>\n",
       "      <td>28.90</td>\n",
       "      <td>29.44</td>\n",
       "      <td>28.70</td>\n",
       "      <td>28.84</td>\n",
       "      <td>11192558</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2014-01-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2014-01-16</td>\n",
       "      <td>28.94</td>\n",
       "      <td>29.39</td>\n",
       "      <td>28.70</td>\n",
       "      <td>29.34</td>\n",
       "      <td>7034698</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2014-01-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2014-01-17</td>\n",
       "      <td>29.30</td>\n",
       "      <td>30.02</td>\n",
       "      <td>29.17</td>\n",
       "      <td>30.02</td>\n",
       "      <td>18304949</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2014-01-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2014-01-21</td>\n",
       "      <td>30.66</td>\n",
       "      <td>30.80</td>\n",
       "      <td>30.20</td>\n",
       "      <td>30.66</td>\n",
       "      <td>10612821</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2014-01-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2014-01-22</td>\n",
       "      <td>30.71</td>\n",
       "      <td>31.24</td>\n",
       "      <td>30.65</td>\n",
       "      <td>31.20</td>\n",
       "      <td>7583631</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2014-01-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>2017-06-30</td>\n",
       "      <td>49.92</td>\n",
       "      <td>50.51</td>\n",
       "      <td>49.60</td>\n",
       "      <td>50.32</td>\n",
       "      <td>6618701</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2017-06-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>2017-07-03</td>\n",
       "      <td>50.78</td>\n",
       "      <td>51.28</td>\n",
       "      <td>50.37</td>\n",
       "      <td>50.39</td>\n",
       "      <td>2906524</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2017-07-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>2017-07-05</td>\n",
       "      <td>50.44</td>\n",
       "      <td>51.54</td>\n",
       "      <td>50.18</td>\n",
       "      <td>51.26</td>\n",
       "      <td>5157516</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2017-07-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>2017-07-06</td>\n",
       "      <td>50.97</td>\n",
       "      <td>52.58</td>\n",
       "      <td>50.86</td>\n",
       "      <td>52.05</td>\n",
       "      <td>7021422</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2017-07-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>2017-07-07</td>\n",
       "      <td>52.30</td>\n",
       "      <td>53.38</td>\n",
       "      <td>52.18</td>\n",
       "      <td>53.03</td>\n",
       "      <td>6596952</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2017-07-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>2017-07-10</td>\n",
       "      <td>52.98</td>\n",
       "      <td>53.16</td>\n",
       "      <td>52.23</td>\n",
       "      <td>52.66</td>\n",
       "      <td>4600014</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2017-07-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902</th>\n",
       "      <td>2017-07-11</td>\n",
       "      <td>52.58</td>\n",
       "      <td>52.66</td>\n",
       "      <td>51.47</td>\n",
       "      <td>51.61</td>\n",
       "      <td>4545699</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2017-07-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>2017-07-12</td>\n",
       "      <td>53.12</td>\n",
       "      <td>53.82</td>\n",
       "      <td>52.45</td>\n",
       "      <td>53.80</td>\n",
       "      <td>8348363</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2017-07-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>904</th>\n",
       "      <td>2017-07-13</td>\n",
       "      <td>53.40</td>\n",
       "      <td>54.48</td>\n",
       "      <td>53.15</td>\n",
       "      <td>53.81</td>\n",
       "      <td>5346686</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2017-07-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>905</th>\n",
       "      <td>2017-07-14</td>\n",
       "      <td>53.80</td>\n",
       "      <td>54.28</td>\n",
       "      <td>53.34</td>\n",
       "      <td>54.22</td>\n",
       "      <td>4537895</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2017-07-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>2017-07-17</td>\n",
       "      <td>54.21</td>\n",
       "      <td>54.28</td>\n",
       "      <td>53.85</td>\n",
       "      <td>53.87</td>\n",
       "      <td>3727804</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2017-07-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>907</th>\n",
       "      <td>2017-07-18</td>\n",
       "      <td>53.83</td>\n",
       "      <td>53.84</td>\n",
       "      <td>53.02</td>\n",
       "      <td>53.15</td>\n",
       "      <td>4101431</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2017-07-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>2017-07-19</td>\n",
       "      <td>52.26</td>\n",
       "      <td>53.19</td>\n",
       "      <td>51.78</td>\n",
       "      <td>52.61</td>\n",
       "      <td>5774713</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2017-07-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>909</th>\n",
       "      <td>2017-07-20</td>\n",
       "      <td>52.72</td>\n",
       "      <td>52.78</td>\n",
       "      <td>52.10</td>\n",
       "      <td>52.34</td>\n",
       "      <td>4836234</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2017-07-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>2017-07-21</td>\n",
       "      <td>52.13</td>\n",
       "      <td>52.55</td>\n",
       "      <td>51.45</td>\n",
       "      <td>51.91</td>\n",
       "      <td>4544423</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2017-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>2017-07-24</td>\n",
       "      <td>51.79</td>\n",
       "      <td>52.03</td>\n",
       "      <td>51.24</td>\n",
       "      <td>51.28</td>\n",
       "      <td>4876393</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2017-07-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>2017-07-25</td>\n",
       "      <td>51.50</td>\n",
       "      <td>51.90</td>\n",
       "      <td>50.54</td>\n",
       "      <td>50.61</td>\n",
       "      <td>4484890</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2017-07-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>2017-07-26</td>\n",
       "      <td>50.63</td>\n",
       "      <td>51.16</td>\n",
       "      <td>50.01</td>\n",
       "      <td>51.01</td>\n",
       "      <td>4776112</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2017-07-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>2017-07-27</td>\n",
       "      <td>50.34</td>\n",
       "      <td>50.34</td>\n",
       "      <td>48.75</td>\n",
       "      <td>50.00</td>\n",
       "      <td>10260337</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2017-07-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>2017-07-28</td>\n",
       "      <td>49.02</td>\n",
       "      <td>50.67</td>\n",
       "      <td>48.73</td>\n",
       "      <td>50.49</td>\n",
       "      <td>9153445</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2017-07-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>2017-07-31</td>\n",
       "      <td>50.85</td>\n",
       "      <td>51.23</td>\n",
       "      <td>50.04</td>\n",
       "      <td>50.44</td>\n",
       "      <td>6062854</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2017-07-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>2017-08-01</td>\n",
       "      <td>51.13</td>\n",
       "      <td>52.00</td>\n",
       "      <td>50.32</td>\n",
       "      <td>51.06</td>\n",
       "      <td>5045298</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2017-08-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>2017-08-02</td>\n",
       "      <td>50.89</td>\n",
       "      <td>51.18</td>\n",
       "      <td>49.90</td>\n",
       "      <td>50.45</td>\n",
       "      <td>4679746</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2017-08-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>2017-08-03</td>\n",
       "      <td>50.56</td>\n",
       "      <td>51.20</td>\n",
       "      <td>50.36</td>\n",
       "      <td>50.55</td>\n",
       "      <td>3231366</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2017-08-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>2017-08-04</td>\n",
       "      <td>50.67</td>\n",
       "      <td>50.92</td>\n",
       "      <td>50.39</td>\n",
       "      <td>50.80</td>\n",
       "      <td>2993515</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2017-08-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>2017-08-07</td>\n",
       "      <td>50.82</td>\n",
       "      <td>51.13</td>\n",
       "      <td>50.46</td>\n",
       "      <td>50.58</td>\n",
       "      <td>3016726</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2017-08-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>2017-08-08</td>\n",
       "      <td>50.68</td>\n",
       "      <td>50.78</td>\n",
       "      <td>49.89</td>\n",
       "      <td>50.00</td>\n",
       "      <td>4274416</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2017-08-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>2017-08-09</td>\n",
       "      <td>49.74</td>\n",
       "      <td>49.92</td>\n",
       "      <td>49.23</td>\n",
       "      <td>49.40</td>\n",
       "      <td>5020809</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2017-08-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924</th>\n",
       "      <td>2017-08-10</td>\n",
       "      <td>49.03</td>\n",
       "      <td>49.34</td>\n",
       "      <td>48.19</td>\n",
       "      <td>48.55</td>\n",
       "      <td>5441375</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2017-08-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925</th>\n",
       "      <td>2017-08-11</td>\n",
       "      <td>48.50</td>\n",
       "      <td>48.78</td>\n",
       "      <td>47.44</td>\n",
       "      <td>48.35</td>\n",
       "      <td>5610688</td>\n",
       "      <td>AAL</td>\n",
       "      <td>2017-08-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>926 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date   Open   High    Low  Close    Volume Name trading_date\n",
       "0    2013-12-09  23.85  25.44  23.45  24.60  43197268  AAL   2013-12-09\n",
       "1    2013-12-10  24.50  25.17  24.41  24.88  18660625  AAL   2013-12-10\n",
       "2    2013-12-11  25.48  27.20  25.37  25.99  38843371  AAL   2013-12-11\n",
       "3    2013-12-12  26.20  26.71  25.45  25.45  19981824  AAL   2013-12-12\n",
       "4    2013-12-13  25.75  26.30  25.52  26.23  12192421  AAL   2013-12-13\n",
       "5    2013-12-16  26.63  26.77  26.35  26.61  13190945  AAL   2013-12-16\n",
       "6    2013-12-17  26.48  26.59  25.95  26.10  11413199  AAL   2013-12-17\n",
       "7    2013-12-18  25.99  26.23  25.55  26.23   9994162  AAL   2013-12-18\n",
       "8    2013-12-19  26.12  26.49  25.82  26.12   6916497  AAL   2013-12-19\n",
       "9    2013-12-20  26.18  26.49  26.14  26.33   8530924  AAL   2013-12-20\n",
       "10   2013-12-23  26.29  26.49  26.05  26.18   5403084  AAL   2013-12-23\n",
       "11   2013-12-24  26.00  26.26  26.00  26.25   2652974  AAL   2013-12-24\n",
       "12   2013-12-26  26.12  26.36  25.98  26.13   4226639  AAL   2013-12-26\n",
       "13   2013-12-27  25.95  26.10  24.91  24.94  13227018  AAL   2013-12-27\n",
       "14   2013-12-30  24.87  25.25  24.65  24.78   8841369  AAL   2013-12-30\n",
       "15   2013-12-31  24.74  25.25  24.63  25.25   7168395  AAL   2013-12-31\n",
       "16   2014-01-02  25.07  25.82  25.06  25.36   8998943  AAL   2014-01-02\n",
       "17   2014-01-03  25.75  26.75  25.51  26.54  13836062  AAL   2014-01-03\n",
       "18   2014-01-06  26.62  27.20  26.60  27.03  11272273  AAL   2014-01-06\n",
       "19   2014-01-07  27.20  27.40  26.67  26.90  11288775  AAL   2014-01-07\n",
       "20   2014-01-08  26.37  27.68  26.35  27.63  15736891  AAL   2014-01-08\n",
       "21   2014-01-09  28.24  29.60  28.20  29.42  26056445  AAL   2014-01-09\n",
       "22   2014-01-10  29.05  29.83  28.75  29.35  12824160  AAL   2014-01-10\n",
       "23   2014-01-13  29.18  29.53  28.58  28.65  10591701  AAL   2014-01-13\n",
       "24   2014-01-14  28.75  29.04  28.71  28.87  10601529  AAL   2014-01-14\n",
       "25   2014-01-15  28.90  29.44  28.70  28.84  11192558  AAL   2014-01-15\n",
       "26   2014-01-16  28.94  29.39  28.70  29.34   7034698  AAL   2014-01-16\n",
       "27   2014-01-17  29.30  30.02  29.17  30.02  18304949  AAL   2014-01-17\n",
       "28   2014-01-21  30.66  30.80  30.20  30.66  10612821  AAL   2014-01-21\n",
       "29   2014-01-22  30.71  31.24  30.65  31.20   7583631  AAL   2014-01-22\n",
       "..          ...    ...    ...    ...    ...       ...  ...          ...\n",
       "896  2017-06-30  49.92  50.51  49.60  50.32   6618701  AAL   2017-06-30\n",
       "897  2017-07-03  50.78  51.28  50.37  50.39   2906524  AAL   2017-07-03\n",
       "898  2017-07-05  50.44  51.54  50.18  51.26   5157516  AAL   2017-07-05\n",
       "899  2017-07-06  50.97  52.58  50.86  52.05   7021422  AAL   2017-07-06\n",
       "900  2017-07-07  52.30  53.38  52.18  53.03   6596952  AAL   2017-07-07\n",
       "901  2017-07-10  52.98  53.16  52.23  52.66   4600014  AAL   2017-07-10\n",
       "902  2017-07-11  52.58  52.66  51.47  51.61   4545699  AAL   2017-07-11\n",
       "903  2017-07-12  53.12  53.82  52.45  53.80   8348363  AAL   2017-07-12\n",
       "904  2017-07-13  53.40  54.48  53.15  53.81   5346686  AAL   2017-07-13\n",
       "905  2017-07-14  53.80  54.28  53.34  54.22   4537895  AAL   2017-07-14\n",
       "906  2017-07-17  54.21  54.28  53.85  53.87   3727804  AAL   2017-07-17\n",
       "907  2017-07-18  53.83  53.84  53.02  53.15   4101431  AAL   2017-07-18\n",
       "908  2017-07-19  52.26  53.19  51.78  52.61   5774713  AAL   2017-07-19\n",
       "909  2017-07-20  52.72  52.78  52.10  52.34   4836234  AAL   2017-07-20\n",
       "910  2017-07-21  52.13  52.55  51.45  51.91   4544423  AAL   2017-07-21\n",
       "911  2017-07-24  51.79  52.03  51.24  51.28   4876393  AAL   2017-07-24\n",
       "912  2017-07-25  51.50  51.90  50.54  50.61   4484890  AAL   2017-07-25\n",
       "913  2017-07-26  50.63  51.16  50.01  51.01   4776112  AAL   2017-07-26\n",
       "914  2017-07-27  50.34  50.34  48.75  50.00  10260337  AAL   2017-07-27\n",
       "915  2017-07-28  49.02  50.67  48.73  50.49   9153445  AAL   2017-07-28\n",
       "916  2017-07-31  50.85  51.23  50.04  50.44   6062854  AAL   2017-07-31\n",
       "917  2017-08-01  51.13  52.00  50.32  51.06   5045298  AAL   2017-08-01\n",
       "918  2017-08-02  50.89  51.18  49.90  50.45   4679746  AAL   2017-08-02\n",
       "919  2017-08-03  50.56  51.20  50.36  50.55   3231366  AAL   2017-08-03\n",
       "920  2017-08-04  50.67  50.92  50.39  50.80   2993515  AAL   2017-08-04\n",
       "921  2017-08-07  50.82  51.13  50.46  50.58   3016726  AAL   2017-08-07\n",
       "922  2017-08-08  50.68  50.78  49.89  50.00   4274416  AAL   2017-08-08\n",
       "923  2017-08-09  49.74  49.92  49.23  49.40   5020809  AAL   2017-08-09\n",
       "924  2017-08-10  49.03  49.34  48.19  48.55   5441375  AAL   2017-08-10\n",
       "925  2017-08-11  48.50  48.78  47.44  48.35   5610688  AAL   2017-08-11\n",
       "\n",
       "[926 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-96b402d84e02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# load dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#read_csv('pollution.csv', header=0, index_col=0)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'trading_date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "#read_csv('pollution.csv', header=0, index_col=0)\n",
    "dataset = dataset.drop('Name', 1)\n",
    "dataset = dataset.drop('Date', 1)\n",
    "dataset.set_index(['trading_date'], inplace=True)\n",
    "values = dataset.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)   var4(t)\n",
      "1   0.000000   0.008701   0.000000   0.000000   0.997838  0.008986\n",
      "2   0.020287   0.000000   0.030563   0.008986   0.934054  0.044608\n",
      "3   0.050874   0.065421   0.061127   0.044608   0.992432  0.027279\n",
      "4   0.073346   0.049629   0.063674   0.027279   0.948108  0.052311\n",
      "5   0.059301   0.036416   0.065903   0.052311   0.753514  0.064506\n"
     ]
    }
   ],
   "source": [
    "# integer encode direction\n",
    "encoder = LabelEncoder()\n",
    "values[:,4] = encoder.fit_transform(values[:,4])\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, 1, 1)\n",
    "# drop columns we don't want to predict\n",
    "reframed.drop(reframed.columns[[5, 6, 7, 9]], axis=1, inplace=True)\n",
    "print(reframed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "values = reframed.values\n",
    "train_len = int(len(values) * 0.80)\n",
    "test_len = len(values) - train_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "740\n",
      "185\n"
     ]
    }
   ],
   "source": [
    "print(train_len)\n",
    "print(test_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = values[0:train_len]\n",
    "test = values[train_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "[[ 0.          0.00870132  0.          0.          0.99783784  0.00898588]\n",
      " [ 0.0202871   0.          0.03056347  0.00898588  0.93405408  0.04460847]\n",
      " [ 0.05087388  0.06542063  0.06112701  0.04460847  0.99243248  0.0272786 ]\n",
      " ..., \n",
      " [ 0.58863914  0.5871737   0.59535176  0.56803596  0.47027028  0.58825421]\n",
      " [ 0.56866407  0.57299387  0.58038837  0.58825421  0.24108109  0.60333776]\n",
      " [ 0.59800243  0.59426367  0.6217764   0.60333776  0.37513515  0.64698339]]\n",
      "Test\n",
      "[[ 0.66011226  0.64808249  0.64119703  0.64698339  0.80216217  0.63703477]\n",
      " [ 0.64950061  0.63261354  0.65202159  0.63703477  0.19351351  0.68132234]\n",
      " [ 0.64107358  0.66645181  0.65584201  0.68132234  0.45297298  0.695122  ]\n",
      " ..., \n",
      " [ 0.83739066  0.82533026  0.84176999  0.81514776  0.04108108  0.79589236]\n",
      " [ 0.80805242  0.79761517  0.82075769  0.79589236  0.08972973  0.7686137 ]\n",
      " [ 0.78589249  0.77892363  0.78764719  0.7686137   0.12        0.76219511]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Train\")\n",
    "print(train)\n",
    "print(\"Test\")\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(740, 1, 5) (740,) (185, 1, 5) (185,)\n"
     ]
    }
   ],
   "source": [
    "X_train = train[:, :-1]\n",
    "y_train = train[:, -1]\n",
    "X_test = test[:, :-1]\n",
    "y_test = test[:, -1]\n",
    "\n",
    "# reshape\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from numpy import concatenate\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn_model = Sequential()\n",
    "rnn_model.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "rnn_model.add(Dense(1))\n",
    "rnn_model.compile(loss='mae', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 740 samples, validate on 185 samples\n",
      "Epoch 1/50\n",
      "0s - loss: 0.0518 - val_loss: 0.0630\n",
      "Epoch 2/50\n",
      "0s - loss: 0.0478 - val_loss: 0.0566\n",
      "Epoch 3/50\n",
      "0s - loss: 0.0440 - val_loss: 0.0488\n",
      "Epoch 4/50\n",
      "0s - loss: 0.0405 - val_loss: 0.0424\n",
      "Epoch 5/50\n",
      "0s - loss: 0.0374 - val_loss: 0.0362\n",
      "Epoch 6/50\n",
      "0s - loss: 0.0347 - val_loss: 0.0304\n",
      "Epoch 7/50\n",
      "0s - loss: 0.0324 - val_loss: 0.0264\n",
      "Epoch 8/50\n",
      "0s - loss: 0.0306 - val_loss: 0.0247\n",
      "Epoch 9/50\n",
      "0s - loss: 0.0291 - val_loss: 0.0234\n",
      "Epoch 10/50\n",
      "0s - loss: 0.0281 - val_loss: 0.0231\n",
      "Epoch 11/50\n",
      "0s - loss: 0.0275 - val_loss: 0.0225\n",
      "Epoch 12/50\n",
      "0s - loss: 0.0270 - val_loss: 0.0223\n",
      "Epoch 13/50\n",
      "0s - loss: 0.0266 - val_loss: 0.0224\n",
      "Epoch 14/50\n",
      "0s - loss: 0.0264 - val_loss: 0.0224\n",
      "Epoch 15/50\n",
      "0s - loss: 0.0263 - val_loss: 0.0224\n",
      "Epoch 16/50\n",
      "0s - loss: 0.0261 - val_loss: 0.0224\n",
      "Epoch 17/50\n",
      "0s - loss: 0.0260 - val_loss: 0.0227\n",
      "Epoch 18/50\n",
      "0s - loss: 0.0260 - val_loss: 0.0225\n",
      "Epoch 19/50\n",
      "0s - loss: 0.0259 - val_loss: 0.0227\n",
      "Epoch 20/50\n",
      "0s - loss: 0.0259 - val_loss: 0.0226\n",
      "Epoch 21/50\n",
      "0s - loss: 0.0259 - val_loss: 0.0229\n",
      "Epoch 22/50\n",
      "0s - loss: 0.0258 - val_loss: 0.0227\n",
      "Epoch 23/50\n",
      "0s - loss: 0.0258 - val_loss: 0.0231\n",
      "Epoch 24/50\n",
      "0s - loss: 0.0258 - val_loss: 0.0228\n",
      "Epoch 25/50\n",
      "0s - loss: 0.0258 - val_loss: 0.0231\n",
      "Epoch 26/50\n",
      "0s - loss: 0.0257 - val_loss: 0.0229\n",
      "Epoch 27/50\n",
      "0s - loss: 0.0257 - val_loss: 0.0232\n",
      "Epoch 28/50\n",
      "0s - loss: 0.0257 - val_loss: 0.0230\n",
      "Epoch 29/50\n",
      "0s - loss: 0.0257 - val_loss: 0.0232\n",
      "Epoch 30/50\n",
      "0s - loss: 0.0257 - val_loss: 0.0230\n",
      "Epoch 31/50\n",
      "0s - loss: 0.0257 - val_loss: 0.0232\n",
      "Epoch 32/50\n",
      "0s - loss: 0.0256 - val_loss: 0.0230\n",
      "Epoch 33/50\n",
      "0s - loss: 0.0256 - val_loss: 0.0233\n",
      "Epoch 34/50\n",
      "0s - loss: 0.0256 - val_loss: 0.0230\n",
      "Epoch 35/50\n",
      "0s - loss: 0.0256 - val_loss: 0.0233\n",
      "Epoch 36/50\n",
      "0s - loss: 0.0256 - val_loss: 0.0230\n",
      "Epoch 37/50\n",
      "0s - loss: 0.0256 - val_loss: 0.0233\n",
      "Epoch 38/50\n",
      "0s - loss: 0.0256 - val_loss: 0.0229\n",
      "Epoch 39/50\n",
      "0s - loss: 0.0256 - val_loss: 0.0235\n",
      "Epoch 40/50\n",
      "0s - loss: 0.0255 - val_loss: 0.0229\n",
      "Epoch 41/50\n",
      "0s - loss: 0.0255 - val_loss: 0.0234\n",
      "Epoch 42/50\n",
      "0s - loss: 0.0255 - val_loss: 0.0229\n",
      "Epoch 43/50\n",
      "0s - loss: 0.0255 - val_loss: 0.0235\n",
      "Epoch 44/50\n",
      "0s - loss: 0.0255 - val_loss: 0.0229\n",
      "Epoch 45/50\n",
      "0s - loss: 0.0255 - val_loss: 0.0235\n",
      "Epoch 46/50\n",
      "0s - loss: 0.0254 - val_loss: 0.0230\n",
      "Epoch 47/50\n",
      "0s - loss: 0.0254 - val_loss: 0.0234\n",
      "Epoch 48/50\n",
      "0s - loss: 0.0254 - val_loss: 0.0229\n",
      "Epoch 49/50\n",
      "0s - loss: 0.0254 - val_loss: 0.0235\n",
      "Epoch 50/50\n",
      "0s - loss: 0.0254 - val_loss: 0.0228\n"
     ]
    }
   ],
   "source": [
    "history = rnn_model.fit(X_train, y_train, epochs=50, batch_size=72, validation_data=(X_test, y_test), verbose=2, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngP8f/tJ0TKz+Y5UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f92b6e7ecf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yhat = rnn_model.predict(X_test)\n",
    "X_test = X_test.reshape((X_test.shape[0], X_test.shape[2]))\n",
    "inv_yhat = concatenate((yhat, X_test[:, 1:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = y_test.reshape((len(y_test), 1))\n",
    "inv_y = concatenate((y_test, X_test[:,1:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rmse = sqrt(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " l;asjfsdlk f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is for comparing the different columns of the raw data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[['Open', 'High', 'Low', 'Close']].plot()\n",
    "plt.show()\n",
    "df['Volume'].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is graphing a few of the graphs with the opening price and the volume on one graph to compare with two different axis'.  I thought to do this as a comparison between the opening price (which all the raw data features follow roughly the same line) and the volume feature.  Since the volume feature is important. [http://www.investopedia.com/terms/v/volume.asp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getting_preprocessed_data(symbol):\n",
    "        csv_file = '{}/{}_data.csv'.format(directory, symbol)\n",
    "        df = pd.read_csv(csv_file)\n",
    "        df = df.drop('Name', 1)\n",
    "        df.set_index('Date', inplace=True)\n",
    "        # below was found at https://stackoverflow.com/questions/29314033/python-pandas-dataframe-remove-empty-cells\n",
    "        df['Open'].replace('', np.nan, inplace=True)\n",
    "        df.dropna(subset=['Open'], inplace=True)\n",
    "        return df\n",
    "\n",
    "def plotting_stocks(symbols_list, amount_of_stocks=0):\n",
    "    if amount_of_stocks == 0:\n",
    "        amount_of_stocks = len(symbols_list)\n",
    "        \n",
    "    for symbol in symbols_list[:amount_of_stocks]:\n",
    "        fig, ax = plt.subplots()\n",
    "        fig.subplots_adjust(right=0.7)\n",
    "        df = getting_preprocessed_data(symbol)\n",
    "        print(symbol)\n",
    "        df.Open.plot(ax=ax, style='b-', figsize=(20,10))\n",
    "        # same ax as above since it's automatically added on the right\n",
    "        df.Volume.plot(ax=ax, style='r-', secondary_y=True, figsize=(20,10))\n",
    "        # add legend --> take advantage of pandas providing us access\n",
    "        # to the line associated with the right part of the axis\n",
    "        #ax.legend([ax.get_lines()[0], ax.get_lines()[0]], ['Open','Volume'], bbox_to_anchor=(1.5, 0.5))\n",
    "        plt.show()\n",
    "        #below is the Daily Returns calculation to put into the Sharpe Ratio. \n",
    "        df_preprocessed = df.assign(Daily_Returns = np.divide((df.Open - df.Close), df.Close) * 100)\n",
    "\n",
    "        #Below is the calculation for the Sharpe Ratio column. \n",
    "        df_preprocessed = df_preprocessed.assign(Sharpe_Ratio = np.divide((df_preprocessed.Daily_Returns - 0.046), np.std(np.array([df_preprocessed.Open, df_preprocessed.High, df_preprocessed.Low, df_preprocessed.Close]))))\n",
    "\n",
    "        #Below is the rate of change (momentum) for the specific stock. \n",
    "        df_preprocessed = df_preprocessed.assign(Rate_of_Change = (np.divide(df_preprocessed.Close, df_preprocessed.Open) - 1) * 100)\n",
    "\n",
    "        #df.plot.scatter(x='Open', y='Volume', label=\"AAL\")\n",
    "        log_df = np.log(df)\n",
    "        log_df.plot.scatter(x='Volume', y='Open', label=\"AAL\", figsize=(20,10))\n",
    "        plt.show()\n",
    "        df_preprocessed.plot.scatter(x='Open', y='Sharpe_Ratio', label=\"Sharpe Ratio Open\", figsize=(20,10))\n",
    "        plt.show()\n",
    "        df_preprocessed.plot.scatter(x='Volume',y='Sharpe_Ratio', label=\"Sharpe Ratio Close\", figsize=(20,10), use_index=True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# printing out the first four stocks to get an idea of how each stock is individually represented.\n",
    "plotting_stocks(symbols_list, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#df.plot.scatter(x='Open', y='Volume', label=\"AAL\")\n",
    "log_df = np.log(df)\n",
    "log_df.plot.scatter(x='Volume', y='Open', label=\"AAL\", figsize=(20,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "log_df.plot.scatter(x='Volume', y='Close', label=\"AAL\", figsize=(20,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "log_df.plot(x=log_df.index, y='Open', label=\"AAL\", figsize=(20,10), use_index=True, style='.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#below is the Daily Returns calculation to put into the Sharpe Ratio. \n",
    "df_preprocessed = df.assign(Daily_Returns = np.divide((df.Open - df.Close), df.Close) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Below is the calculation for the Sharpe Ratio column. \n",
    "df_preprocessed = df_preprocessed.assign(Sharpe_Ratio = np.divide((df_preprocessed.Daily_Returns - 0.046), np.std(np.array([df_preprocessed.Open, df_preprocessed.High, df_preprocessed.Low, df_preprocessed.Close]), ddof=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Below is the rate of change for the specific stock. \n",
    "df_preprocessed = df_preprocessed.assign(Rate_of_Change = (np.divide(df_preprocessed.Close, df_preprocessed.Open) - 1) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_preprocessed.plot.scatter(x='Volume', y='Sharpe_Ratio', label=\"AAL\", figsize=(20,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "display(df_preprocessed.head(n=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I am using some of the techniques I learned from previous projects.  The below is from the Finding Donors Project.\n",
    "closing = df_preprocessed['Close'].astype(int)\n",
    "features = df_preprocessed.drop('Close', axis = 1)\n",
    "\n",
    "#closing_raw\n",
    "#features_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, closing, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = SVC(random_state=2)\n",
    "\n",
    "learner = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, pred)*100\n",
    "\n",
    "print(\"Accuracy is: {:.4f}%\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# This next section will be the creation of the RNN-LSTM model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some information gathered from https://machinelearningmastery.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From my research and many hours of trial and error I have discovered that the preprocessing needs to be different for the RNN-LSTM as compared to the SVC.  https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_rnn = np.array(features)\n",
    "closing_rnn = np.array(closing)\n",
    "\n",
    "features_train_len = int(len(features_rnn) * 0.80)\n",
    "features_test_len = int(len(features_rnn) - features_train_len)\n",
    "\n",
    "X_train = features_rnn[0:features_train_len]\n",
    "X_test = features_rnn[features_test_len:len(features_rnn)]\n",
    "\n",
    "y_train = closing_rnn[0:features_train_len]\n",
    "y_test = closing_rnn[features_test_len:len(closing_rnn)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(1, features_train_len, 7)\n",
    "y_train = y_train.reshape(1, features_train_len, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn_model = Sequential()\n",
    "rnn_model.add(LSTM(32, input_shape=(740, 7)))\n",
    "rnn_model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn_model.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
