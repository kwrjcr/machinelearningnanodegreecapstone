{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is my capstone project for the Udacity Machine Learning Nanodegree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the libraries needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras as kr\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "directory = 'sandp500/individual_stocks_5yr'\n",
    "#directory = '/OneDrive/Documents/Projects/MachineLearning/Udacity/Capstone/sandp500/individual_stocks_5yr'\n",
    "dir_listing = listdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "504\n",
      "AAL\n"
     ]
    }
   ],
   "source": [
    "symbols_list = []\n",
    "\n",
    "for symbol in dir_listing:\n",
    "    symb = symbol.split('_')[0]\n",
    "    symbols_list.append(symb)\n",
    "\n",
    "print(len(symbols_list))\n",
    "print(symbols_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_file = '{}/{}_data.csv'.format(directory, symbols_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we already know the name of the specific stock we are trying to get from the name of the file, we can drop that column in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.assign(trading_date = pd.to_datetime(dataset['Date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# below code is copied from: https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/\n",
    "\n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "\tn_vars = 1 if type(data) is list else data.shape[1]\n",
    "\tdf = pd.DataFrame(data)\n",
    "\tcols, names = list(), list()\n",
    "\t# input sequence (t-n, ... t-1)\n",
    "\tfor i in range(n_in, 0, -1):\n",
    "\t\tcols.append(df.shift(i))\n",
    "\t\tnames += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# forecast sequence (t, t+1, ... t+n)\n",
    "\tfor i in range(0, n_out):\n",
    "\t\tcols.append(df.shift(-i))\n",
    "\t\tif i == 0:\n",
    "\t\t\tnames += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "\t\telse:\n",
    "\t\t\tnames += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "\t# put it all together\n",
    "\tagg = pd.concat(cols, axis=1)\n",
    "\tagg.columns = names\n",
    "\t# drop rows with NaN values\n",
    "\tif dropnan:\n",
    "\t\tagg.dropna(inplace=True)\n",
    "\treturn agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "#read_csv('pollution.csv', header=0, index_col=0)\n",
    "dataset = dataset.drop('Name', 1)\n",
    "dataset = dataset.drop('Date', 1)\n",
    "dataset.set_index(['trading_date'], inplace=True)\n",
    "values = dataset.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)   var1(t)   var2(t)  \\\n",
      "1   0.000000   0.008701   0.000000   0.000000   0.997838  0.020287  0.000000   \n",
      "2   0.020287   0.000000   0.030563   0.008986   0.934054  0.050874  0.065421   \n",
      "3   0.050874   0.065421   0.061127   0.044608   0.992432  0.073346  0.049629   \n",
      "4   0.073346   0.049629   0.063674   0.027279   0.948108  0.059301  0.036416   \n",
      "5   0.059301   0.036416   0.065903   0.052311   0.753514  0.086766  0.051563   \n",
      "\n",
      "    var3(t)   var4(t)   var5(t)  \n",
      "1  0.030563  0.008986  0.934054  \n",
      "2  0.061127  0.044608  0.992432  \n",
      "3  0.063674  0.027279  0.948108  \n",
      "4  0.065903  0.052311  0.753514  \n",
      "5  0.092327  0.064506  0.805405  \n"
     ]
    }
   ],
   "source": [
    "# integer encode direction\n",
    "encoder = LabelEncoder()\n",
    "values[:,4] = encoder.fit_transform(values[:,4])\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, 1, 1)\n",
    "# drop columns we don't want to predict\n",
    "#reframed.drop(reframed.columns[[9,10,11,12,13,14,15]], axis=1, inplace=True)\n",
    "print(reframed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is for comparing the different columns of the raw data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['Open', 'High', 'Low', 'Close']].plot()\n",
    "plt.show()\n",
    "df['Volume'].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is graphing a few of the graphs with the opening price and the volume on one graph to compare with two different axis'.  I thought to do this as a comparison between the opening price (which all the raw data features follow roughly the same line) and the volume feature.  Since the volume feature is important. [http://www.investopedia.com/terms/v/volume.asp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getting_preprocessed_data(symbol):\n",
    "        csv_file = '{}/{}_data.csv'.format(directory, symbol)\n",
    "        df = pd.read_csv(csv_file)\n",
    "        df = df.drop('Name', 1)\n",
    "        df.set_index('Date', inplace=True)\n",
    "        # below was found at https://stackoverflow.com/questions/29314033/python-pandas-dataframe-remove-empty-cells\n",
    "        df['Open'].replace('', np.nan, inplace=True)\n",
    "        df.dropna(subset=['Open'], inplace=True)\n",
    "        return df\n",
    "\n",
    "def plotting_stocks(symbols_list, amount_of_stocks=0):\n",
    "    if amount_of_stocks == 0:\n",
    "        amount_of_stocks = len(symbols_list)\n",
    "        \n",
    "    for symbol in symbols_list[:amount_of_stocks]:\n",
    "        fig, ax = plt.subplots()\n",
    "        fig.subplots_adjust(right=0.7)\n",
    "        df = getting_preprocessed_data(symbol)\n",
    "        print(symbol)\n",
    "        df.Open.plot(ax=ax, style='b-', figsize=(20,10))\n",
    "        # same ax as above since it's automatically added on the right\n",
    "        df.Volume.plot(ax=ax, style='r-', secondary_y=True, figsize=(20,10))\n",
    "        # add legend --> take advantage of pandas providing us access\n",
    "        # to the line associated with the right part of the axis\n",
    "        #ax.legend([ax.get_lines()[0], ax.get_lines()[0]], ['Open','Volume'], bbox_to_anchor=(1.5, 0.5))\n",
    "        plt.show()\n",
    "        #below is the Daily Returns calculation to put into the Sharpe Ratio. \n",
    "        df_preprocessed = df.assign(Daily_Returns = np.divide((df.Open - df.Close), df.Close) * 100)\n",
    "\n",
    "        #Below is the calculation for the Sharpe Ratio column. \n",
    "        df_preprocessed = df_preprocessed.assign(Sharpe_Ratio = np.divide((df_preprocessed.Daily_Returns - 0.046), np.std(np.array([df_preprocessed.Open, df_preprocessed.High, df_preprocessed.Low, df_preprocessed.Close]))))\n",
    "\n",
    "        #Below is the rate of change (momentum) for the specific stock. \n",
    "        df_preprocessed = df_preprocessed.assign(Rate_of_Change = (np.divide(df_preprocessed.Close, df_preprocessed.Open) - 1) * 100)\n",
    "\n",
    "        #df.plot.scatter(x='Open', y='Volume', label=\"AAL\")\n",
    "        log_df = np.log(df)\n",
    "        log_df.plot.scatter(x='Volume', y='Open', label=\"AAL\", figsize=(20,10))\n",
    "        plt.show()\n",
    "        df_preprocessed.plot.scatter(x='Open', y='Sharpe_Ratio', label=\"Sharpe Ratio Open\", figsize=(20,10))\n",
    "        plt.show()\n",
    "        df_preprocessed.plot.scatter(x='Volume',y='Sharpe_Ratio', label=\"Sharpe Ratio Close\", figsize=(20,10), use_index=True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# printing out the first four stocks to get an idea of how each stock is individually represented.\n",
    "plotting_stocks(symbols_list, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#df.plot.scatter(x='Open', y='Volume', label=\"AAL\")\n",
    "log_df = np.log(df)\n",
    "log_df.plot.scatter(x='Volume', y='Open', label=\"AAL\", figsize=(20,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "log_df.plot.scatter(x='Volume', y='Close', label=\"AAL\", figsize=(20,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "log_df.plot(x=log_df.index, y='Open', label=\"AAL\", figsize=(20,10), use_index=True, style='.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#below is the Daily Returns calculation to put into the Sharpe Ratio. \n",
    "df_preprocessed = df.assign(Daily_Returns = np.divide((df.Open - df.Close), df.Close) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Below is the calculation for the Sharpe Ratio column. \n",
    "df_preprocessed = df_preprocessed.assign(Sharpe_Ratio = np.divide((df_preprocessed.Daily_Returns - 0.046), np.std(np.array([df_preprocessed.Open, df_preprocessed.High, df_preprocessed.Low, df_preprocessed.Close]), ddof=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Below is the rate of change for the specific stock. \n",
    "df_preprocessed = df_preprocessed.assign(Rate_of_Change = (np.divide(df_preprocessed.Close, df_preprocessed.Open) - 1) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed.plot.scatter(x='Volume', y='Sharpe_Ratio', label=\"AAL\", figsize=(20,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "display(df_preprocessed.head(n=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I am using some of the techniques I learned from previous projects.  The below is from the Finding Donors Project.\n",
    "closing = df_preprocessed['Close'].astype(int)\n",
    "features = df_preprocessed.drop('Close', axis = 1)\n",
    "\n",
    "#closing_raw\n",
    "#features_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, closing, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = SVC(random_state=2)\n",
    "\n",
    "learner = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, pred)*100\n",
    "\n",
    "print(\"Accuracy is: {:.4f}%\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# This next section will be the creation of the RNN-LSTM model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some information gathered from https://machinelearningmastery.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From my research and many hours of trial and error I have discovered that the preprocessing needs to be different for the RNN-LSTM as compared to the SVC.  https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_rnn = np.array(features)\n",
    "closing_rnn = np.array(closing)\n",
    "\n",
    "features_train_len = int(len(features_rnn) * 0.80)\n",
    "features_test_len = int(len(features_rnn) - features_train_len)\n",
    "\n",
    "X_train = features_rnn[0:features_train_len]\n",
    "X_test = features_rnn[features_test_len:len(features_rnn)]\n",
    "\n",
    "y_train = closing_rnn[0:features_train_len]\n",
    "y_test = closing_rnn[features_test_len:len(closing_rnn)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(1, features_train_len, 7)\n",
    "y_train = y_train.reshape(1, features_train_len, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    kaldkfjasdfklj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model = Sequential()\n",
    "rnn_model.add(LSTM(32, input_shape=(740, 7)))\n",
    "rnn_model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model.fit(X_train, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
