{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is my capstone project for the Udacity Machine Learning Nanodegree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the libraries needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras as kr\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'sandp500/individual_stocks_5yr'\n",
    "#directory = 'OneDrive/Documents/Projects/MachineLearning/Udacity/Capstone/sandp500/individual_stocks_5yr'\n",
    "#directory = 'Capstone/sandp500/individual_stocks_5yr'\n",
    "directory_listing = listdir(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols_list = []\n",
    "\n",
    "for symbol in directory_listing:\n",
    "    symb = symbol.split('_')[0]\n",
    "    symbols_list.append(symb)\n",
    "\n",
    "print(len(symbols_list))\n",
    "print(symbols_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_file = '{}/{}_data.csv'.format(directory, symbols_list[0])\n",
    "dataset = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we already know the name of the specific stock we are trying to get from the name of the file, we can drop that column in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.assign(trading_date = pd.to_datetime(dataset['Date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.drop('Name', 1)\n",
    "dataset = dataset.drop('Date', 1)\n",
    "dataset.set_index(['trading_date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset['NextDayClose'] = dataset['Close'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#below is the Daily Returns calculation to put into the Sharpe Ratio. \n",
    "#df = dataset.assign(Daily_Returns = np.divide((dataset.Open - dataset.Close), dataset.Close) * 100)\n",
    "\n",
    "#Below is the calculation for the Sharpe Ratio column. \n",
    "#df = df.assign(Sharpe_Ratio = np.divide((df.Daily_Returns - 0.046), np.std(np.array([df.Open, df.High, df.Low, df.Close]))))\n",
    "\n",
    "#Below is the rate of change (momentum) for the specific stock. \n",
    "#df = df.assign(Rate_of_Change = (np.divide(df.Close, df.Open) - 1) * 100)\n",
    "\n",
    "df = dataset.assign(Difference_of_Close = dataset['Close'].diff())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is for comparing the different columns of the raw data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Open', 'High', 'Low', 'Volume'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is graphing a few of the graphs with the opening price and the volume on one graph to compare with two different axis'.  I thought to do this as a comparison between the opening price (which all the raw data features follow roughly the same line) and the volume feature.  Since the volume feature is important. [http://www.investopedia.com/terms/v/volume.asp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getting_preprocessed_data(symbol):\n",
    "        csv_file = '{}/{}_data.csv'.format(directory, symbol)\n",
    "        df = pd.read_csv(csv_file)\n",
    "        df = df.drop('Name', 1)\n",
    "        df.set_index('Date', inplace=True)\n",
    "        # below was found at https://stackoverflow.com/questions/29314033/python-pandas-dataframe-remove-empty-cells\n",
    "        df['Open'].replace('', np.nan, inplace=True)\n",
    "        df.dropna(subset=['Open'], inplace=True)\n",
    "        return df\n",
    "\n",
    "def plotting_stocks(symbols_list, amount_of_stocks=0):\n",
    "    if amount_of_stocks == 0:\n",
    "        amount_of_stocks = len(symbols_list)\n",
    "        \n",
    "    for symbol in symbols_list[:amount_of_stocks]:\n",
    "        fig, ax = plt.subplots()\n",
    "        fig.subplots_adjust(right=0.7)\n",
    "        df = getting_preprocessed_data(symbol)\n",
    "        print(symbol)\n",
    "        df.Open.plot(ax=ax, style='b-', figsize=(20,10))\n",
    "        # same ax as above since it's automatically added on the right\n",
    "        df.Volume.plot(ax=ax, style='r-', secondary_y=True, figsize=(20,10))\n",
    "        # add legend --> take advantage of pandas providing us access\n",
    "        # to the line associated with the right part of the axis\n",
    "        #ax.legend([ax.get_lines()[0], ax.get_lines()[0]], ['Open','Volume'], bbox_to_anchor=(1.5, 0.5))\n",
    "        plt.show()\n",
    "        #below is the Daily Returns calculation to put into the Sharpe Ratio. \n",
    "        df_preprocessed = df.assign(Daily_Returns = np.divide((df.Open - df.Close), df.Close) * 100)\n",
    "\n",
    "        #Below is the calculation for the Sharpe Ratio column. \n",
    "        df_preprocessed = df_preprocessed.assign(Sharpe_Ratio = np.divide((df_preprocessed.Daily_Returns - 0.046), np.std(np.array([df_preprocessed.Open, df_preprocessed.High, df_preprocessed.Low, df_preprocessed.Close]))))\n",
    "\n",
    "        #Below is the rate of change (momentum) for the specific stock. \n",
    "        df_preprocessed = df_preprocessed.assign(Rate_of_Change = (np.divide(df_preprocessed.Close, df_preprocessed.Open) - 1) * 100)\n",
    "\n",
    "        #df.plot.scatter(x='Open', y='Volume', label=\"AAL\")\n",
    "        log_df = np.log(df)\n",
    "        log_df.plot.scatter(x='Volume', y='Open', label=\"AAL\", figsize=(20,10))\n",
    "        plt.show()\n",
    "        df_preprocessed.plot.scatter(x='Open', y='Sharpe_Ratio', label=\"Sharpe Ratio Open\", figsize=(20,10))\n",
    "        plt.show()\n",
    "        df_preprocessed.plot.scatter(x='Volume',y='Sharpe_Ratio', label=\"Sharpe Ratio Close\", figsize=(20,10), use_index=True)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# printing out the first four stocks to get an idea of how each stock is individually represented.\n",
    "plotting_stocks(symbols_list, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#df.plot.scatter(x='Open', y='Volume', label=\"AAL\")\n",
    "log_df = np.log(df)\n",
    "log_df.plot.scatter(x='Volume', y='Open', label=\"AAL\", figsize=(20,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "log_df.plot.scatter(x='Volume', y='Close', label=\"AAL\", figsize=(20,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "log_df.plot(x=log_df.index, y='Open', label=\"AAL\", figsize=(20,10), use_index=True, style='.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#below is the Daily Returns calculation to put into the Sharpe Ratio. \n",
    "df_preprocessed = df.assign(Daily_Returns = np.divide((df.Open - df.Close), df.Close) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Below is the calculation for the Sharpe Ratio column. \n",
    "df_preprocessed = df_preprocessed.assign(Sharpe_Ratio = np.divide((df_preprocessed.Daily_Returns - 0.046), np.std(np.array([df_preprocessed.Open, df_preprocessed.High, df_preprocessed.Low, df_preprocessed.Close]), ddof=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Below is the rate of change for the specific stock. \n",
    "df_preprocessed = df_preprocessed.assign(Rate_of_Change = (np.divide(df_preprocessed.Close, df_preprocessed.Open) - 1) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed.plot.scatter(x='Volume', y='Sharpe_Ratio', label=\"AAL\", figsize=(20,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_preprocessed.to_csv('AAL_preprocessed_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_preprocessed_abs = df_preprocessed.assign(Daily_Returns = np.absolute(df_preprocessed.Daily_Returns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_preprocessed_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "display(df_preprocessed.head(n=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I am using some of the techniques I learned from previous projects.  The below is from the Finding Donors Project.\n",
    "closing = df_preprocessed['Close'].astype(int)\n",
    "features = df_preprocessed.drop('Close', axis = 1)\n",
    "\n",
    "#closing_raw\n",
    "#features_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, closing, test_size=0.2, random_state=0)\n",
    "\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = SVC(random_state=2)\n",
    "\n",
    "learner = clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, pred)*100\n",
    "\n",
    "print(\"Accuracy is: {:.4f}%\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
